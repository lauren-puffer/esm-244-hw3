---
title: "ESM 244 - HW3 - Task 2"
author: "Lauren Puffer"
format: html
editor: visual
embed-resources: true
code-fold: show
execute: 
  warning: false
  message: false
toc: TRUE
theme: journal
---

## Overview

!!!! USE LAB 6 KEY!!!

## Load packages

```{r}
library(tidymodels)
library(tidyverse)
library(ggcorrplot)
library(knitr)
library(kableExtra)
library(vip)
library(ranger)

#file management packages
library(janitor)
library(here)
```

## Citation


##Pseudocode

1. Split data maintaining balance

2. Build recipe

3. Set engine

4. Hyperparameter tuning on training set

  a. Build grid to go over parameters
  
  b. Use cross validation to select best parameters
  
  c. Train model on best parameters
  
5. Evaluate model on test set

6. Test for variable importance

##Load forest fire data
Log 10(x+1) 
```{r}
fire_data <- read.csv(here("data","forestfires.csv")) |>
  clean_names() |>
  mutate(area = log10(area+1)) |>
  select(temp, rain, area, wind, rh) |>
  drop_na()
```

##Exploratory Data Analysis
```{r}
fire_data |> 
  cor() |>
  ggcorrplot(
    method = "circle",
    type='upper',
    outline.col = "black",
  )
```



##Split data
```{r}
set.seed(666)

fire_split <- initial_split(fire_data, prop = 0.75, strata = area)

fire_train <- training(fire_split)

fire_test <- testing(fire_split)
```


##Create recipe
```{r}
fire_recipe <- recipe(area ~ ., data = fire_train) |> 
  step_zv(all_predictors()) |> 
  step_corr(all_predictors(), threshold = 0.9) #variables that are 90% or more w correlation
```

##Create a workflow for regression
Tune parameters with tidymodels using the tune() function. 
```{r}
fire_spec <- rand_forest(trees = 1000, 
                       mtry = tune(),
                       min_n=tune()) |>
  set_engine("ranger") |>
  set_mode("regression")

fire_workflow <- workflow() |>
  add_recipe(fire_recipe) |>
  add_model(fire_spec)
```

##Tune hyperparameters
```{r}
#create 12 possible gridsusing expand_grid() function
fire_grid <- expand_grid(
  mtry = seq(1, 4, by = 1), 
  min_n = seq(1, 3, by = 1)  
)

#tune grid to the workflow and resample
fire_res <- tune_grid(
  fire_workflow,
  resamples = vfold_cv(fire_train, v = 10),
  grid = fire_grid,
  metrics = metric_set(mae),
  control=control_grid(save_workflow = TRUE)  
)
```

##Model performance
Look at how well the model performed with different parameters

```{r}
fire_res |>
  collect_metrics() |>
  filter(.metric == "mae") |>
  mutate(min_n = factor(min_n)) |>
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, linewidth = 1.5) +
  geom_point() +
  labs(y = "Mean Absolute Error", x = "Number of Parameters Used")
```

##Select the best fit
```{r}

fire_best<-select_best(fire_res,metric='mae')

fire_final<-finalize_model(fire_spec, fire_best)

# finalize workflow

final_fire_wf <- workflow() |>
  add_recipe(fire_recipe) |>
  add_model(fire_final)

final_fire_res <- final_fire_wf |>
  last_fit(fire_split)

```

